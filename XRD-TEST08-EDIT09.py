# XRDç‰¹å¾æå–å·¥å…· - ç¡¬ç¢³ä¸“é¡¹åˆ†æ
# ä¸“æ³¨XRDå…¨å±€ç‰¹å¾æå–ï¼Œå¸¦æ‰‹åŠ¨åŸºçº¿è°ƒæ•´åŠŸèƒ½

import streamlit as st
import numpy as np
import pandas as pd
import matplotlib
# å¼ºåˆ¶ä½¿ç”¨éäº¤äº’å¼åç«¯ï¼Œè§£å†³å¤šæ˜¾ç¤ºå™¨é—®é¢˜
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from scipy.signal import find_peaks, peak_widths, savgol_filter
from scipy.integrate import simpson
from scipy.optimize import curve_fit
import os
import base64
from scipy import sparse
from scipy.sparse.linalg import spsolve
import time
from scipy import stats
from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression

# é«˜æ–¯å‡½æ•°ç”¨äºå³°æ‹Ÿåˆ
def gaussian(x, a, b, c):
    return a * np.exp(-(x - b)**2 / (2 * c**2))

# æ´›ä¼¦å…¹å‡½æ•°ç”¨äºå³°æ‹Ÿåˆ
def lorentzian(x, a, b, c):
    return a / (1 + ((x - b) / c)**2)

# æ•°æ®å½’ä¸€åŒ–å‡½æ•°
def normalize_data(intensity):
    """å°†å¼ºåº¦æ•°æ®å½’ä¸€åŒ–åˆ°0-1èŒƒå›´"""
    min_val = np.min(intensity)
    max_val = np.max(intensity)
    if max_val - min_val > 0:
        return (intensity - min_val) / (max_val - min_val)
    else:
        return intensity

# ä¸¤ç§ä¸åŒçš„èƒŒæ™¯æ‰£é™¤ç®—æ³•
def asymmetric_least_squares_precise(y, lam=1e6, p=0.01, n_iter=10):
    """
    ç²¾ç¡®æ¨¡å¼ï¼šåŸå§‹ALSèƒŒæ™¯æ‰£é™¤ç®—æ³•
    ä½¿ç”¨ç¨ å¯†çŸ©é˜µï¼Œå‡†ç¡®æ€§é«˜ä½†é€Ÿåº¦è¾ƒæ…¢
    """
    L = len(y)
    # æ„é€ äºŒé˜¶å·®åˆ†çŸ©é˜µ (L-2) x L
    D = np.diff(np.eye(L), 2, axis=0)
    w = np.ones(L)
    z = np.zeros(L)
    
    for i in range(n_iter):
        # æ„é€ å¯¹è§’æƒé‡çŸ©é˜µ
        W = np.diag(w)
        # æ„é€ ç³»ç»ŸçŸ©é˜µ
        Z = W + lam * D.T @ D
        # æ±‚è§£çº¿æ€§ç³»ç»Ÿ
        z = np.linalg.solve(Z, w * y)
        # æ›´æ–°æƒé‡
        w = p * (y > z) + (1 - p) * (y <= z)
        
    return z

def asymmetric_least_squares_fast(y, lam=1e6, p=0.01, n_iter=5):
    """
    å¿«é€Ÿæ¨¡å¼ï¼šä¼˜åŒ–çš„ALSèƒŒæ™¯æ‰£é™¤ç®—æ³•
    ä½¿ç”¨ç¨€ç–çŸ©é˜µå¤§å¹…æé«˜æ€§èƒ½ï¼Œé€‚åˆå¤§æ•°æ®é›†
    """
    L = len(y)
    
    # æ„é€ ç¨€ç–äºŒé˜¶å·®åˆ†çŸ©é˜µ
    diag_data = np.ones(L)
    D = sparse.diags([diag_data, -2*diag_data, diag_data], [0, -1, -2], shape=(L, L-2), format='csc')
    
    w = np.ones(L)
    z = np.zeros(L)
    
    # é¢„è®¡ç®—ç¨€ç–çŸ©é˜µ
    DDT = lam * D.dot(D.T)
    
    for i in range(n_iter):
        # æ„é€ ç¨€ç–å¯¹è§’æƒé‡çŸ©é˜µ
        W = sparse.diags(w, 0, shape=(L, L), format='csc')
        
        # ç»„åˆçŸ©é˜µ
        A = W + DDT
        
        # æ±‚è§£çº¿æ€§ç³»ç»Ÿ
        try:
            z = spsolve(A, w * y)
        except Exception as e:
            st.error(f"èƒŒæ™¯æ‰£é™¤å¤±è´¥: {str(e)}")
            return y  # è¿”å›åŸå§‹æ•°æ®ä½œä¸ºåå¤‡
        
        # æ›´æ–°æƒé‡
        w = p * (y > z) + (1 - p) * (y <= z)
    
    return z

# ä¿®æ”¹åçš„åŸºçº¿å¤„ç†å‡½æ•° - æ”¯æŒæ‰‹åŠ¨èµ·ç‚¹ç»ˆç‚¹é€‰æ‹©
def modified_background_correction(angle, intensity, peak_ranges, manual_points=None, mode='precise', progress_callback=None):
    """
    èƒŒæ™¯æ‰£é™¤å‡½æ•°ï¼Œæ”¯æŒæ‰‹åŠ¨é€‰æ‹©èµ·ç‚¹ç»ˆç‚¹
    manual_points: å­—å…¸ï¼Œæ ¼å¼ä¸º {hkl: (start_angle, end_angle)}
    """
    # åˆå§‹åŒ–è¿›åº¦
    if progress_callback:
        progress_callback(0, f"å¼€å§‹èƒŒæ™¯æ‰£é™¤ ({mode}æ¨¡å¼)...")
    
    # æ ¹æ®æ¨¡å¼é€‰æ‹©ç®—æ³•
    if mode == 'precise':
        # ç²¾ç¡®æ¨¡å¼
        if progress_callback:
            progress_callback(10, "ä½¿ç”¨ç²¾ç¡®æ¨¡å¼è¿›è¡ŒèƒŒæ™¯æ‰£é™¤...")
        background = asymmetric_least_squares_precise(intensity, lam=1e7, p=0.001, n_iter=10)
    else:  # 'fast'
        # å¿«é€Ÿæ¨¡å¼
        if progress_callback:
            progress_callback(10, "ä½¿ç”¨å¿«é€Ÿæ¨¡å¼è¿›è¡ŒèƒŒæ™¯æ‰£é™¤...")
        background = asymmetric_least_squares_fast(intensity, lam=1e7, p=0.001, n_iter=5)
    
    if progress_callback:
        progress_callback(30, "èƒŒæ™¯æ‰£é™¤å®Œæˆï¼Œä¿®æ­£åŸºçº¿ä¸­...")
    
    # åˆ›å»ºä¿®æ­£åçš„åŸºçº¿ï¼ˆåˆå§‹ä¸ºALSåŸºçº¿ï¼‰
    modified_background = background.copy()
    
    # å¯¹æ¯ä¸ªå³°èŒƒå›´è¿›è¡Œçº¿æ€§åŸºçº¿ä¿®æ­£
    total_ranges = len(peak_ranges)
    for idx, (low, high, hkl) in enumerate(peak_ranges):
        if progress_callback:
            progress = 30 + int((idx+1)/total_ranges*70)
            progress_callback(progress, f"ä¿®æ­£{hkl}æ™¶é¢èƒŒæ™¯ ({idx+1}/{total_ranges})")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ‰‹åŠ¨è®¾ç½®çš„èµ·ç‚¹ç»ˆç‚¹
        if manual_points and hkl in manual_points:
            manual_low, manual_high = manual_points[hkl]
            # ä½¿ç”¨æ‰‹åŠ¨è®¾ç½®çš„èŒƒå›´
            mask = (angle >= manual_low) & (angle <= manual_high)
        else:
            # ä½¿ç”¨é»˜è®¤èŒƒå›´
            mask = (angle >= low) & (angle <= high)
        
        range_angles = angle[mask]
        
        if len(range_angles) < 2:
            continue
        
        # è·å–èŒƒå›´èµ·ç‚¹å’Œç»ˆç‚¹çš„èƒŒæ™¯å€¼
        start_idx = np.where(angle == range_angles[0])[0][0]
        end_idx = np.where(angle == range_angles[-1])[0][0]
        
        start_val = background[start_idx]
        end_val = background[end_idx]
        
        # åˆ›å»ºçº¿æ€§åŸºçº¿ï¼ˆä»èµ·ç‚¹åˆ°ç»ˆç‚¹ï¼‰
        linear_bg = np.linspace(start_val, end_val, len(range_angles))
        
        # æ›¿æ¢è¯¥èŒƒå›´å†…çš„åŸºçº¿ä¸ºçº¿æ€§åŸºçº¿
        modified_background[mask] = linear_bg
    
    # ä½¿ç”¨ä¿®æ­£åçš„åŸºçº¿è¿›è¡ŒèƒŒæ™¯æ‰£é™¤
    corrected_intensity = intensity - modified_background
    
    return corrected_intensity, modified_background, background

# æå–XRDå…¨å±€ç‰¹å¾å‡½æ•°
def extract_global_features(angle, intensity, corrected_intensity):
    """æå–XRDæ•°æ®çš„å…¨å±€ç‰¹å¾"""
    features = {}
    
    # åŸºæœ¬ç»Ÿè®¡ç‰¹å¾
    features['global_max_intensity'] = np.max(intensity)
    features['global_min_intensity'] = np.min(intensity)
    features['global_mean_intensity'] = np.mean(intensity)
    features['global_std_intensity'] = np.std(intensity)
    
    # èƒŒæ™¯æ‰£é™¤åçš„ç»Ÿè®¡ç‰¹å¾
    features['corrected_max_intensity'] = np.max(corrected_intensity)
    features['corrected_min_intensity'] = np.min(corrected_intensity)
    features['corrected_mean_intensity'] = np.mean(corrected_intensity)
    features['corrected_std_intensity'] = np.std(corrected_intensity)
    
    # ç§¯åˆ†é¢ç§¯ç‰¹å¾
    features['total_integral_area'] = simpson(intensity, angle)
    features['corrected_integral_area'] = simpson(corrected_intensity, angle)
    
    # å³°æ•°é‡ç‰¹å¾ (åœ¨æ•´ä¸ªèŒƒå›´å†…)
    min_prominence = 0.05 * np.max(corrected_intensity)
    peaks, _ = find_peaks(corrected_intensity, prominence=min_prominence)
    features['total_peak_count'] = len(peaks)
    
    # å³°ä½ç½®åˆ†å¸ƒç‰¹å¾
    if len(peaks) > 0:
        peak_positions = angle[peaks]
        features['mean_peak_position'] = np.mean(peak_positions)
        features['std_peak_position'] = np.std(peak_positions)
        features['min_peak_position'] = np.min(peak_positions)
        features['max_peak_position'] = np.max(peak_positions)
    else:
        features['mean_peak_position'] = np.nan
        features['std_peak_position'] = np.nan
        features['min_peak_position'] = np.nan
        features['max_peak_position'] = np.nan
    
    # å³°é«˜åˆ†å¸ƒç‰¹å¾
    if len(peaks) > 0:
        peak_heights = corrected_intensity[peaks]
        features['mean_peak_height'] = np.mean(peak_heights)
        features['max_peak_height'] = np.max(peak_heights)
    else:
        features['mean_peak_height'] = np.nan
        features['max_peak_height'] = np.nan
    
    # è®¡ç®—ä¿¡å™ªæ¯” (SNR)
    noise_region = np.where((angle > 80) & (angle < 85))[0]  # å‡è®¾80-85åº¦èŒƒå›´ä¸»è¦æ˜¯å™ªå£°
    if len(noise_region) > 10:
        noise_std = np.std(corrected_intensity[noise_region])
        if noise_std > 0:
            features['snr'] = np.max(corrected_intensity) / noise_std
        else:
            features['snr'] = np.nan
    else:
        features['snr'] = np.nan
    
    return features

# è®¡ç®—å †å å±‚æ•°
def calculate_stacking_layers(peak_position, L_value):
    """è®¡ç®—å †å å±‚æ•°"""
    Î» = 1.5406  # Cu KÎ±æ³¢é•¿ (Ã…)
    
    # å¸ƒæ‹‰æ ¼å…¬å¼è®¡ç®—å±‚é—´è· d = Î»/(2sinÎ¸)
    Î¸ = np.deg2rad(peak_position / 2)  # å¸ƒæ‹‰æ ¼è§’(å¼§åº¦)
    d_spacing = Î» / (2 * np.sin(Î¸))
    
    # å †å å±‚æ•° = æ™¶ç²’å°ºå¯¸ / å±‚é—´è·
    if d_spacing > 0:
        stacking_layers = L_value / d_spacing
    else:
        stacking_layers = np.nan
    
    return stacking_layers, d_spacing

# XRDç‰¹å¾æå–å‡½æ•°ï¼ˆå¸¦è¿›åº¦åé¦ˆï¼‰
def extract_xrd_features(angle, intensity, peak_ranges=None, manual_points=None, bg_mode='precise', progress_callback=None):
    # åˆå§‹åŒ–è¿›åº¦
    if progress_callback:
        progress_callback(0, "å¼€å§‹åˆ†æXRDæ•°æ®...")
    
    # 0. æ•°æ®é¢„å¤„ç† - ä¿®æ”¹åçš„èƒŒæ™¯æ‰£é™¤
    if progress_callback:
        progress_callback(5, "èƒŒæ™¯æ‰£é™¤ä¸­...")
    
    if peak_ranges is None:
        peak_ranges = []
    
    # æ·»åŠ è¿›åº¦å›è°ƒåˆ°èƒŒæ™¯æ‰£é™¤å‡½æ•°
    def bg_callback(progress, message):
        if progress_callback:
            # èƒŒæ™¯æ‰£é™¤å æ€»è¿›åº¦çš„40%
            progress_callback(5 + progress*0.4, message)
    
    corrected_intensity, modified_background, original_background = modified_background_correction(
        angle, intensity, peak_ranges, manual_points=manual_points, mode=bg_mode, progress_callback=bg_callback
    )
    
    # 1. æ•°æ®å¹³æ»‘ (ä½¿ç”¨Savitzky-Golayæ»¤æ³¢å™¨)
    if progress_callback:
        progress_callback(45, "å¹³æ»‘æ•°æ®ä¸­...")
    
    window_size = min(51, len(angle) // 10 * 2 + 1)
    if window_size < 5:
        window_size = 5
        
    smooth_intensity = savgol_filter(corrected_intensity, window_size, 3)
    
    # 2. æå–å…¨å±€ç‰¹å¾
    if progress_callback:
        progress_callback(48, "æå–å…¨å±€ç‰¹å¾...")
    
    global_features = extract_global_features(angle, intensity, corrected_intensity)
    
    # 3. ç‰¹å¾å­˜å‚¨å­—å…¸
    features = global_features.copy()
    
    # 4. å¦‚æœæ²¡æœ‰æŒ‡å®šå³°èŒƒå›´ï¼Œåˆ™åˆ†ææ•´ä¸ªèŒƒå›´
    if not peak_ranges:
        peak_ranges = [(np.min(angle), np.max(angle), 'unknown')]
    
    # 5. éå†æ‰€æœ‰æŒ‡å®šçš„å³°èŒƒå›´
    figs = []
    total_ranges = len(peak_ranges)
    
    # å­˜å‚¨æ™¶ç²’å°ºå¯¸ç”¨äºè®¡ç®—æ¯”å€¼
    Lc_value = None
    La_value = None
    
    for i, (low, high, hkl) in enumerate(peak_ranges):
        # æ£€æŸ¥æ˜¯å¦æœ‰æ‰‹åŠ¨è®¾ç½®çš„èŒƒå›´
        if manual_points and hkl in manual_points:
            manual_low, manual_high = manual_points[hkl]
            current_low, current_high = manual_low, manual_high
            range_label = f"{manual_low:.1f}-{manual_high:.1f}Â°"
        else:
            current_low, current_high = low, high
            range_label = f"{low}-{high}Â°"
        
        # æ›´æ–°è¿›åº¦
        progress_percent = 50 + int((i / total_ranges) * 50)
        if progress_percent > 100:
            progress_percent = 100
            
        if progress_callback:
            progress_callback(progress_percent, f"åˆ†æ{hkl}æ™¶é¢èŒƒå›´ ({range_label})...")
        
        # åˆ›å»ºå½“å‰å³°èŒƒå›´çš„æ©ç 
        mask = (angle >= current_low) & (angle <= current_high)
        range_angles = angle[mask]
        range_intensity = smooth_intensity[mask]
        
        if len(range_angles) < 10:
            st.warning(f"åœ¨èŒƒå›´ {current_low}-{current_high} å†…æ•°æ®ç‚¹ä¸è¶³ï¼ˆ{len(range_angles)}ä¸ªï¼‰ï¼")
            prefix = f"peak_{hkl}_" if hkl != 'unknown' else f"peak_{i+1}_"
            features.update({
                f"{prefix}position": np.nan,
                f"{prefix}height": np.nan,
                f"{prefix}fwhm": np.nan,
                f"{prefix}area": np.nan
            })
            continue
        
        # 6. åœ¨å½“å‰èŒƒå›´å†…æ£€æµ‹å³°
        min_prominence = 0.05 * max(range_intensity)
        min_width = max(2, len(range_angles) * 0.01)
        
        peaks, properties = find_peaks(range_intensity, 
                                      prominence=min_prominence, 
                                      width=min_width,
                                      rel_height=0.5)
        
        if len(peaks) == 0:
            st.warning(f"åœ¨èŒƒå›´ {current_low}-{current_high} å†…æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„å³°ï¼")
            prefix = f"peak_{hkl}_" if hkl != 'unknown' else f"peak_{i+1}_"
            features.update({
                f"{prefix}position": np.nan,
                f"{prefix}height": np.nan,
                f"{prefix}fwhm": np.nan,
                f"{prefix}area": np.nan
            })
            continue
        
        # 7. æ‰¾åˆ°å½“å‰èŒƒå›´å†…çš„ä¸»å³° (æœ€é«˜å³°)
        main_peak_idx = np.argmax(properties['prominences'])
        main_peak = peaks[main_peak_idx]
        peak_position = range_angles[main_peak]
        peak_height = range_intensity[main_peak]
        
        # 8. é«˜æ–¯æ‹Ÿåˆç²¾ä¿®å³°å‚æ•°
        try:
            # é€‰æ‹©æ‹ŸåˆèŒƒå›´ï¼šÂ±3å€åŠé«˜å®½
            half_width = properties['widths'][main_peak_idx] / 2
            fit_start = max(0, int(main_peak - 3 * half_width))
            fit_end = min(len(range_angles), int(main_peak + 3 * half_width))
            
            fit_angles = range_angles[fit_start:fit_end]
            fit_intensity = range_intensity[fit_start:fit_end]
            
            # åˆå§‹å‚æ•°ä¼°è®¡
            p0 = [peak_height, peak_position, half_width * (range_angles[1]-range_angles[0])]
            
            # é«˜æ–¯æ‹Ÿåˆ
            popt, pcov = curve_fit(gaussian, fit_angles, fit_intensity, p0=p0,
                                  maxfev=5000)  # å¢åŠ æœ€å¤§è¯„ä¼°æ¬¡æ•°
            
            # æ›´æ–°å³°å‚æ•°
            peak_position = popt[1]
            peak_height = popt[0]
            fwhm = 2 * np.sqrt(2 * np.log(2)) * abs(popt[2])  # FWHM = 2.355 * Ïƒ
            
            # è®¡ç®—å³°é¢ç§¯ (åŸºäºæ‹Ÿåˆæ›²çº¿)
            x_fine = np.linspace(min(fit_angles), max(fit_angles), 500)
            y_fine = gaussian(x_fine, *popt)
            peak_area = simpson(y_fine, x_fine)
            
            fit_success = True
        except Exception as e:
            st.warning(f"é«˜æ–¯æ‹Ÿåˆå¤±è´¥: {str(e)}ï¼Œä½¿ç”¨åŸå§‹æ–¹æ³•")
            widths = peak_widths(range_intensity, [main_peak], rel_height=0.5)
            fwhm = widths[0][0] * (range_angles[1]-range_angles[0])
            
            # è®¡ç®—å³°é¢ç§¯ (è‡ªé€‚åº”èŒƒå›´ï¼šÂ±5å€åŠé«˜å®½)
            half_width_points = int(5 * widths[0][0])
            start_idx = max(0, main_peak - half_width_points)
            end_idx = min(len(range_angles), main_peak + half_width_points)
            peak_area = simpson(range_intensity[start_idx:end_idx], range_angles[start_idx:end_idx])
            fit_success = False
        
        # 9. ä½¿ç”¨æ™¶é¢æŒ‡æ•°ä½œä¸ºå‰ç¼€
        prefix = f"peak_{hkl}_" if hkl != 'unknown' else f"peak_{i+1}_"
        
        # 10. å°†åŸºæœ¬ç‰¹å¾æ·»åŠ åˆ°å­—å…¸
        features.update({
            f"{prefix}position": peak_position,
            f"{prefix}height": peak_height,
            f"{prefix}fwhm": fwhm,
            f"{prefix}area": peak_area
        })
        
        # 11. æ™¶ç²’å°ºå¯¸è®¡ç®— (ä»…å¯¹ç‰¹å®šæ™¶é¢)
        Î» = 1.5406  # Cu KÎ±æ³¢é•¿ (Ã…)
        Î¸ = np.deg2rad(peak_position / 2)  # å¸ƒæ‹‰æ ¼è§’(å¼§åº¦)
        Î² = np.deg2rad(fwhm)  # åŠé«˜å®½(å¼§åº¦)
        
        # é¿å…è¿‡å°çš„Î²å€¼å¯¼è‡´å¼‚å¸¸å¤§çš„æ™¶ç²’å°ºå¯¸
        if Î² < np.deg2rad(0.1):  # 0.1åº¦é˜ˆå€¼
            st.warning(f"åŠé«˜å®½è¿‡å°({fwhm:.4f}åº¦)ï¼Œæ™¶ç²’å°ºå¯¸è®¡ç®—å¯èƒ½ä¸å‡†ç¡®")
            Î² = np.deg2rad(0.5)  # è®¾ç½®æœ€å°å€¼
        
        if hkl == '002':
            # è®¡ç®—Lc (æ²¿cè½´çš„æ™¶ç²’å°ºå¯¸)
            K = 0.89  # ç¡¬ç¢³ææ–™æ¨èå€¼
            Lc = K * Î» / (Î² * np.cos(Î¸))
            features[f"{prefix}Lc"] = Lc
            Lc_value = Lc  # å­˜å‚¨ç”¨äºæ¯”å€¼è®¡ç®—
            
            # è®¡ç®—å †å å±‚æ•°
            stacking_layers, d_spacing = calculate_stacking_layers(peak_position, Lc)
            features[f"{prefix}stacking_layers"] = stacking_layers
            features[f"{prefix}d_spacing"] = d_spacing
            
        elif hkl == '100':
            # è®¡ç®—La (æ²¿aè½´çš„æ™¶ç²’å°ºå¯¸)
            K = 1.84  # å½¢çŠ¶å› å­
            La = K * Î» / (Î² * np.cos(Î¸))
            features[f"{prefix}La"] = La
            La_value = La  # å­˜å‚¨ç”¨äºæ¯”å€¼è®¡ç®—
            
            # è®¡ç®—å †å å±‚æ•°
            stacking_layers, d_spacing = calculate_stacking_layers(peak_position, La)
            features[f"{prefix}stacking_layers"] = stacking_layers
            features[f"{prefix}d_spacing"] = d_spacing
        
        # 12. å¯è§†åŒ–å½“å‰å³°èŒƒå›´ - ä¼˜åŒ–å›¾è¡¨æ˜¾ç¤º
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 12), dpi=100)
        
        # è®¾ç½®å…¨å±€å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial', 'sans-serif']
        plt.rcParams['axes.unicode_minus'] = False
        
        # åŸå§‹æ•°æ®å’Œå¹³æ»‘æ•°æ®
        ax1.plot(angle, intensity, 'b-', label='åŸå§‹æ•°æ®', alpha=0.6)
        ax1.plot(angle, original_background, 'k:', label='åˆå§‹èƒŒæ™¯', linewidth=1.5, alpha=0.7)
        ax1.plot(angle, modified_background, 'k-', label='ä¿®æ­£èƒŒæ™¯', linewidth=2)
        ax1.plot(angle, corrected_intensity, 'g-', label='æ‰£é™¤èƒŒæ™¯', alpha=0.8)
        ax1.plot(angle, smooth_intensity, 'r-', label='å¹³æ»‘æ•°æ®', linewidth=1.5)
        ax1.axvline(peak_position, color='m', linestyle='--', label='å³°ä½ç½®')
        
        # æ ‡è®°æ‰‹åŠ¨è®¾ç½®çš„èµ·ç‚¹ç»ˆç‚¹
        if manual_points and hkl in manual_points:
            manual_low, manual_high = manual_points[hkl]
            ax1.axvline(manual_low, color='orange', linestyle='--', alpha=0.7, label='æ‰‹åŠ¨èµ·ç‚¹')
            ax1.axvline(manual_high, color='orange', linestyle='--', alpha=0.7, label='æ‰‹åŠ¨ç»ˆç‚¹')
        
        ax1.set_xlabel('2Î¸ (åº¦)', fontsize=12)
        ax1.set_ylabel('å¼ºåº¦ (a.u.)', fontsize=12)
        ax1.set_title(f'XRDè°±çº¿é¢„å¤„ç† ({range_label}, {hkl}æ™¶é¢)', fontsize=14, pad=20)
        ax1.legend(loc='best', fontsize=10, framealpha=0.7)
        ax1.grid(True, linestyle='--', alpha=0.7)
        ax1.tick_params(axis='both', which='major', labelsize=10)
        
        # å³°åŒºåŸŸæ”¾å¤§å›¾
        ax2.plot(range_angles, range_intensity, 'b-', label='å¹³æ»‘æ•°æ®')
        ax2.plot(range_angles[main_peak], range_intensity[main_peak], 'ro', label='ä¸»å³°')
        ax2.axvline(peak_position, color='g', linestyle='--', label='å³°ä½ç½®')
        
        # ç»˜åˆ¶æ‹Ÿåˆæ›²çº¿ï¼ˆå¦‚æœæˆåŠŸï¼‰
        if fit_success:
            ax2.plot(x_fine, y_fine, 'm-', label='é«˜æ–¯æ‹Ÿåˆ', linewidth=2)
        
        # æ ‡è®°æ‰‹åŠ¨è®¾ç½®çš„èµ·ç‚¹ç»ˆç‚¹
        if manual_points and hkl in manual_points:
            manual_low, manual_high = manual_points[hkl]
            ax2.axvline(manual_low, color='orange', linestyle='--', alpha=0.7, label='æ‰‹åŠ¨èµ·ç‚¹')
            ax2.axvline(manual_high, color='orange', linestyle='--', alpha=0.7, label='æ‰‹åŠ¨ç»ˆç‚¹')
        
        ax2.set_xlabel('2Î¸ (åº¦)', fontsize=12)
        ax2.set_ylabel('å¼ºåº¦ (a.u.)', fontsize=12)
        ax2.set_title(f'å³°ç‰¹å¾æå– ({range_label}, {hkl}æ™¶é¢)', fontsize=14, pad=20)
        ax2.legend(loc='best', fontsize=10, framealpha=0.7)
        ax2.grid(True, linestyle='--', alpha=0.7)
        ax2.tick_params(axis='both', which='major', labelsize=10)
        
        # è°ƒæ•´å¸ƒå±€
        plt.tight_layout(pad=3.0)
        figs.append(fig)
    
    # æ·»åŠ æ¯”å€¼ç‰¹å¾
    if Lc_value is not None and La_value is not None:
        features['La_Lc_ratio'] = La_value / Lc_value
    
    # æ·»åŠ 002å³°é¢ç§¯ä¸100å³°é¢ç§¯æ¯”å€¼
    if 'peak_002_area' in features and 'peak_100_area' in features:
        if features['peak_100_area'] > 0:
            features['A002_A100_ratio'] = features['peak_002_area'] / features['peak_100_area']
    
    # æ·»åŠ 002å³°é«˜ä¸100å³°é«˜æ¯”å€¼
    if 'peak_002_height' in features and 'peak_100_height' in features:
        if features['peak_100_height'] > 0:
            features['H002_H100_ratio'] = features['peak_002_height'] / features['peak_100_height']
    
    if progress_callback:
        progress_callback(100, "åˆ†æå®Œæˆï¼")
    
    return features, figs

# æ–‡ä»¶ä¸‹è½½å‡½æ•°
def get_table_download_link(df, filename):
    csv = df.to_csv(index=False)
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">ä¸‹è½½CSVæ–‡ä»¶</a>'
    return href

# æ ¼å¼åŒ–æ•°æ®æ¡†ï¼Œåªå¯¹æ•°å€¼åˆ—åº”ç”¨æ ¼å¼åŒ–
def format_dataframe(df):
    """æ ¼å¼åŒ–æ•°æ®æ¡†ï¼Œåªå¯¹æ•°å€¼åˆ—åº”ç”¨æ ¼å¼åŒ–"""
    # åˆ›å»ºä¸€ä¸ªå‰¯æœ¬
    formatted_df = df.copy()
    
    # å¯¹æ•°å€¼åˆ—è¿›è¡Œæ ¼å¼åŒ–
    for col in formatted_df.columns:
        if pd.api.types.is_numeric_dtype(formatted_df[col]):
            # å¯¹æ•°å€¼åˆ—åº”ç”¨æ ¼å¼åŒ–
            formatted_df[col] = formatted_df[col].apply(lambda x: f"{x:.4f}" if pd.notna(x) else "N/A")
    
    return formatted_df

# å•ä¸ªæ–‡ä»¶åˆ†æå‡½æ•°
def analyze_single_file(uploaded_file, peak_ranges, manual_points, bg_mode, progress_callback=None):
    """åˆ†æå•ä¸ªXRDæ–‡ä»¶"""
    try:
        # è¯»å–æ–‡ä»¶
        file_ext = os.path.splitext(uploaded_file.name)[1].lower()
        
        if file_ext == '.csv':
            df = pd.read_csv(uploaded_file)
        else:
            df = pd.read_excel(uploaded_file)
        
        # æ£€æŸ¥æ•°æ®æ ¼å¼
        if len(df.columns) < 2:
            st.error(f"æ–‡ä»¶ {uploaded_file.name} æ ¼å¼é”™è¯¯ï¼Œæ— æ³•å¤„ç†")
            return None, None, None
            
        # æå–è§’åº¦å’Œå¼ºåº¦æ•°æ®
        angle_col = df.columns[0]
        intensity_col = df.columns[1]
        
        angles = df[angle_col].values
        raw_intensities = df[intensity_col].values
        
        # æ•°æ®å½’ä¸€åŒ–
        intensities = normalize_data(raw_intensities)
        
        # æå–ç‰¹å¾
        features, figs = extract_xrd_features(
            angles, 
            intensities, 
            peak_ranges, 
            manual_points=manual_points,
            bg_mode=bg_mode,
            progress_callback=progress_callback
        )
        
        # æ·»åŠ æ–‡ä»¶åä¿¡æ¯
        features['filename'] = uploaded_file.name
        
        return features, figs, (angles, intensities)
        
    except Exception as e:
        st.error(f"å¤„ç†æ–‡ä»¶ {uploaded_file.name} æ—¶å‡ºé”™: {str(e)}")
        return None, None, None

# æ‰¹é‡å¤„ç†å‡½æ•°
def batch_process_files(uploaded_files, peak_ranges, manual_points, bg_mode, progress_callback=None):
    """æ‰¹é‡å¤„ç†å¤šä¸ªXRDæ–‡ä»¶"""
    all_results = []
    all_figs = []  # å­˜å‚¨æ¯ä¸ªæ–‡ä»¶çš„å›¾è¡¨
    all_raw_data = []  # å­˜å‚¨æ¯ä¸ªæ–‡ä»¶çš„åŸå§‹æ•°æ®
    
    for i, uploaded_file in enumerate(uploaded_files):
        if progress_callback:
            progress_callback((i * 100) / len(uploaded_files), f"å¼€å§‹å¤„ç†æ–‡ä»¶ {i+1}/{len(uploaded_files)}: {uploaded_file.name}")
        
        # åˆ†æå•ä¸ªæ–‡ä»¶
        features, figs, raw_data = analyze_single_file(
            uploaded_file, 
            peak_ranges, 
            manual_points,
            bg_mode=bg_mode,
            progress_callback=lambda p, m: progress_callback(
                (i * 80 + p * 0.8) / len(uploaded_files), 
                f"å¤„ç† {uploaded_file.name}: {m}"
            ) if progress_callback else None
        )
        
        if features and figs:
            all_results.append(features)
            all_figs.append((uploaded_file.name, figs))  # å­˜å‚¨æ–‡ä»¶åå’Œå¯¹åº”çš„å›¾è¡¨
            all_raw_data.append((uploaded_file.name, raw_data))  # å­˜å‚¨åŸå§‹æ•°æ®
            
        if progress_callback:
            progress = ((i + 1) * 100) / len(uploaded_files)
            progress_callback(progress, f"å®Œæˆæ–‡ä»¶ {i+1}/{len(uploaded_files)}: {uploaded_file.name}")
                
    return all_results, all_figs, all_raw_data

# æ˜¾ç¤ºåŸå§‹æ•°æ®å›¾
def plot_raw_data(angles, intensities, filename):
    """æ˜¾ç¤ºåŸå§‹æ•°æ®å½’ä¸€åŒ–åçš„å›¾å½¢"""
    fig, ax = plt.subplots(figsize=(10, 6), dpi=100)
    
    # è®¾ç½®å…¨å±€å­—ä½“
    plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False
    
    ax.plot(angles, intensities, 'b-', linewidth=2, alpha=0.8)
    ax.set_xlabel('2Î¸ (åº¦)', fontsize=12)
    ax.set_ylabel('å½’ä¸€åŒ–å¼ºåº¦ (a.u.)', fontsize=12)
    ax.set_title(f'åŸå§‹XRDæ•°æ® - {filename}', fontsize=14, pad=20)
    ax.grid(True, linestyle='--', alpha=0.7)
    ax.tick_params(axis='both', which='major', labelsize=10)
    
    plt.tight_layout()
    return fig

# ä¸»åº”ç”¨
def main():
    # è®¾ç½®é¡µé¢é…ç½®
    st.set_page_config(
        page_title="XRDç‰¹å¾æå–å·¥å…· - ç¡¬ç¢³ä¸“é¡¹åˆ†æ",
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # ç®€çº¦é«˜çº§çš„CSSæ ·å¼
    st.markdown("""
    <style>
    .main-title {
        font-size: 2.5rem;
        color: #1a1a1a;
        text-align: center;
        margin-bottom: 1rem;
        font-weight: 600;
        letter-spacing: -0.5px;
    }
    .sub-title {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: 400;
    }
    .section-header {
        font-size: 1.4rem;
        color: #2c3e50;
        margin: 2rem 0 1rem 0;
        padding-bottom: 0.5rem;
        border-bottom: 2px solid #3498db;
        font-weight: 600;
    }
    .subsection-header {
        font-size: 1.1rem;
        color: #34495e;
        margin: 1.5rem 0 0.8rem 0;
        font-weight: 600;
    }
    .parameter-card {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 1.2rem;
        margin-bottom: 1rem;
        border-left: 4px solid #3498db;
    }
    .result-card {
        background: white;
        border-radius: 8px;
        padding: 1.2rem;
        margin-bottom: 1rem;
        border: 1px solid #e1e8ed;
        box-shadow: 0 2px 4px rgba(0,0,0,0.05);
    }
    .metric-card {
        background: white;
        border-radius: 6px;
        padding: 1rem;
        margin: 0.5rem;
        border: 1px solid #e1e8ed;
        text-align: center;
    }
    .file-selector {
        background: #f8f9fa;
        border-radius: 8px;
        padding: 1rem;
        margin-bottom: 1rem;
        border: 1px solid #dee2e6;
    }
    .progress-container {
        background: white;
        border-radius: 8px;
        padding: 1.2rem;
        margin-bottom: 1rem;
        border: 1px solid #e1e8ed;
    }
    .analysis-tabs {
        margin-top: 1rem;
    }
    .stButton>button {
        background-color: #3498db;
        color: white;
        border: none;
        border-radius: 6px;
        padding: 0.6rem 1.5rem;
        font-weight: 500;
        transition: all 0.3s ease;
    }
    .stButton>button:hover {
        background-color: #2980b9;
        transform: translateY(-1px);
    }
    .download-button {
        background-color: #27ae60 !important;
    }
    .download-button:hover {
        background-color: #219653 !important;
    }
    .sidebar .sidebar-content {
        background-color: #f8f9fa;
    }
    .manual-adjust-note {
        background: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 6px;
        padding: 1rem;
        margin-bottom: 1rem;
        color: #856404;
    }
    .feature-grid {
        display: grid;
        grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
        gap: 1rem;
        margin: 1rem 0;
    }
    .chart-container {
        background: white;
        border-radius: 8px;
        padding: 1rem;
        margin-bottom: 1rem;
        border: 1px solid #e1e8ed;
    }
    .reanalyze-section {
        background: #fff5f5;
        border: 1px solid #fed7d7;
        border-radius: 8px;
        padding: 1.2rem;
        margin-top: 1.5rem;
    }
    </style>
    """, unsafe_allow_html=True)
    
    # åˆå§‹åŒ–session state
    if 'batch_results' not in st.session_state:
        st.session_state.batch_results = None
    if 'batch_figs' not in st.session_state:
        st.session_state.batch_figs = None
    if 'batch_raw_data' not in st.session_state:
        st.session_state.batch_raw_data = None
    if 'current_file_index' not in st.session_state:
        st.session_state.current_file_index = 0
    if 'reanalyze_files' not in st.session_state:
        st.session_state.reanalyze_files = {}
    
    # ä¸»æ ‡é¢˜
    st.markdown('<h1 class="main-title">XRDæ™ºèƒ½ç‰¹å¾æå–å¹³å°</h1>', unsafe_allow_html=True)
    st.markdown('<div class="sub-title">ç¡¬ç¢³ææ–™ä¸“é¡¹åˆ†æ | æ‰¹é‡å¤„ç† | æ™ºèƒ½ç‰¹å¾æå–</div>', unsafe_allow_html=True)
    
    # ä¾§è¾¹æ  - æ‰€æœ‰è®¾ç½®åŠŸèƒ½
    with st.sidebar:
        st.markdown('<div class="section-header">åˆ†æè®¾ç½®</div>', unsafe_allow_html=True)
        
        # æ–‡ä»¶ä¸Šä¼ 
        st.markdown("#### ä¸Šä¼ æ•°æ®æ–‡ä»¶")
        uploaded_files = st.file_uploader(
            "é€‰æ‹©XRDæ•°æ®æ–‡ä»¶", 
            type=["csv", "xlsx", "xls"], 
            accept_multiple_files=True,
            label_visibility="collapsed"
        )
        
        if uploaded_files:
            st.info(f"å·²é€‰æ‹© {len(uploaded_files)} ä¸ªæ–‡ä»¶")
            
            # å³°èŒƒå›´è®¾ç½®
            st.markdown("#### åˆ†æå‚æ•°")
            default_ranges = [(15, 35, '002'), (38, 48, '100')]
            custom_ranges = []
            
            use_default = st.checkbox("ä½¿ç”¨é»˜è®¤å³°èŒƒå›´", value=True)
            
            if not use_default:
                st.text_area("è‡ªå®šä¹‰å³°èŒƒå›´", "15 35 002\n38 48 100", 
                           height=100, 
                           help="æ¯è¡Œä¸€ä¸ªèŒƒå›´ï¼Œæ ¼å¼ï¼šèµ·å§‹è§’åº¦ ç»“æŸè§’åº¦ æ™¶é¢æŒ‡æ•°")
            
            peak_ranges = default_ranges if use_default else custom_ranges
            
            # æ‰‹åŠ¨åŸºçº¿è°ƒæ•´
            st.markdown("#### åŸºçº¿è°ƒæ•´")
            st.markdown('<div class="manual-adjust-note">å¯æ ¹æ®XRDè°±çº¿å®é™…æƒ…å†µæ‰‹åŠ¨è°ƒæ•´åŸºçº¿èŒƒå›´</div>', unsafe_allow_html=True)
            
            manual_points = {}
            
            for i, (low, high, hkl) in enumerate(peak_ranges):
                col1, col2 = st.columns(2)
                with col1:
                    manual_start = st.number_input(
                        f"{hkl}èµ·ç‚¹", 
                        value=float(low),
                        min_value=float(10),
                        max_value=float(50),
                        step=0.1,
                        key=f"start_{hkl}"
                    )
                with col2:
                    manual_end = st.number_input(
                        f"{hkl}ç»ˆç‚¹", 
                        value=float(high),
                        min_value=float(10),
                        max_value=float(50),
                        step=0.1,
                        key=f"end_{hkl}"
                    )
                
                if manual_start != low or manual_end != high:
                    manual_points[hkl] = (manual_start, manual_end)
            
            # èƒŒæ™¯æ‰£é™¤æ¨¡å¼
            st.markdown("#### å¤„ç†æ¨¡å¼")
            bg_mode = st.radio(
                "èƒŒæ™¯æ‰£é™¤æ¨¡å¼",
                options=['precise', 'fast'],
                format_func=lambda x: {'precise': 'ç²¾ç¡®æ¨¡å¼', 'fast': 'å¿«é€Ÿæ¨¡å¼'}[x]
            )
            
            # å¼€å§‹åˆ†ææŒ‰é’®
            st.markdown("---")
            if st.button("å¼€å§‹æ‰¹é‡åˆ†æ", type="primary", use_container_width=True):
                if uploaded_files:
                    progress_container = st.container()
                    with progress_container:
                        st.markdown('<div class="progress-container">', unsafe_allow_html=True)
                        st.markdown("**åˆ†æè¿›åº¦**")
                        progress_bar = st.progress(0)
                        status_text = st.empty()
                        st.markdown('</div>', unsafe_allow_html=True)
                    
                    def update_progress(progress_int, message):
                        progress_float = progress_int / 100.0
                        progress_bar.progress(progress_float)
                        status_text.text(message)
                    
                    with st.spinner("æ­£åœ¨åˆ†æXRDæ•°æ®..."):
                        all_results, all_figs, all_raw_data = batch_process_files(
                            uploaded_files, 
                            peak_ranges, 
                            manual_points,
                            bg_mode=bg_mode,
                            progress_callback=update_progress
                        )
                        
                        progress_container.empty()
                        
                        if all_results:
                            st.session_state.batch_results = all_results
                            st.session_state.batch_figs = all_figs
                            st.session_state.batch_raw_data = all_raw_data
                            st.session_state.current_file_index = 0
                            st.success("åˆ†æå®Œæˆï¼")
                        else:
                            st.error("åˆ†æå¤±è´¥ï¼Œè¯·æ£€æŸ¥æ•°æ®å’Œå‚æ•°è®¾ç½®")
                else:
                    st.warning("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
    
    # ä¸»å†…å®¹åŒºåŸŸ - åªæ˜¾ç¤ºåˆ†æç»“æœ
    if st.session_state.batch_results:
        st.markdown('<div class="section-header">æ‰¹é‡åˆ†æç»“æœ</div>', unsafe_allow_html=True)
        
        # æ‰¹é‡æ±‡æ€»ç»“æœ
        result_df = pd.DataFrame(st.session_state.batch_results)
        formatted_df = format_dataframe(result_df)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("å¤„ç†æ–‡ä»¶æ•°é‡", len(st.session_state.batch_results))
        with col2:
            st.metric("æå–ç‰¹å¾æ•°é‡", len(result_df.columns) - 1)
        with col3:
            st.metric("æˆåŠŸç‡", f"{(len(st.session_state.batch_results)/len(uploaded_files))*100:.1f}%")
        
        st.dataframe(formatted_df, use_container_width=True)
        
        # æ‰¹é‡ä¸‹è½½
        download_filename = f"XRD_batch_analysis_{len(uploaded_files)}_files.csv"
        st.markdown(get_table_download_link(result_df, download_filename), unsafe_allow_html=True)
        
        st.markdown('<div class="section-header">å„æ–‡ä»¶è¯¦ç»†åˆ†æç»“æœ</div>', unsafe_allow_html=True)
        
        # æ–‡ä»¶é€‰æ‹©å™¨ - è§£å†³å¤šæ–‡ä»¶åˆ‡æ¢é—®é¢˜
        st.markdown('<div class="file-selector">', unsafe_allow_html=True)
        col1, col2, col3 = st.columns([2, 1, 1])
        
        with col1:
            file_names = [name for name, _ in st.session_state.batch_figs]
            selected_file = st.selectbox(
                "é€‰æ‹©è¦æŸ¥çœ‹çš„æ–‡ä»¶",
                options=file_names,
                index=st.session_state.current_file_index
            )
            st.session_state.current_file_index = file_names.index(selected_file)
        
        with col2:
            if st.button("ä¸Šä¸€ä¸ªæ–‡ä»¶") and st.session_state.current_file_index > 0:
                st.session_state.current_file_index -= 1
                st.rerun()
        
        with col3:
            if st.button("ä¸‹ä¸€ä¸ªæ–‡ä»¶") and st.session_state.current_file_index < len(file_names) - 1:
                st.session_state.current_file_index += 1
                st.rerun()
        st.markdown('</div>', unsafe_allow_html=True)
        
        # å½“å‰æ–‡ä»¶è¯¦ç»†åˆ†æç»“æœ
        current_index = st.session_state.current_file_index
        filename, file_figs = st.session_state.batch_figs[current_index]
        features_dict = st.session_state.batch_results[current_index]
        
        # æ˜¾ç¤ºåŸå§‹æ•°æ®å›¾
        if st.session_state.batch_raw_data:
            raw_filename, raw_data = st.session_state.batch_raw_data[current_index]
            if raw_data:
                angles, intensities = raw_data
                raw_fig = plot_raw_data(angles, intensities, filename)
                st.markdown('<div class="chart-container">', unsafe_allow_html=True)
                st.markdown("#### åŸå§‹æ•°æ®å›¾")
                st.pyplot(raw_fig)
                st.markdown('</div>', unsafe_allow_html=True)
        
        # ç‰¹å¾å±•ç¤º - ä½¿ç”¨ç½‘æ ¼å¸ƒå±€
        st.markdown('<div class="result-card">', unsafe_allow_html=True)
        st.markdown("#### ç‰¹å¾åˆ†æç»“æœ")
        
        # å…¨å±€ç‰¹å¾
        st.markdown("##### å…¨å±€ç‰¹å¾")
        global_cols = st.columns(3)
        global_features = [
            ('total_peak_count', 'æ€»å³°æ•°é‡'),
            ('global_mean_intensity', 'å¹³å‡å¼ºåº¦'), 
            ('corrected_mean_intensity', 'æ ¡æ­£å¼ºåº¦'),
            ('total_integral_area', 'æ€»ç§¯åˆ†é¢ç§¯'),
            ('corrected_integral_area', 'æ ¡æ­£é¢ç§¯'),
            ('snr', 'ä¿¡å™ªæ¯”')
        ]
        
        for i, (key, name) in enumerate(global_features):
            if key in features_dict:
                with global_cols[i % 3]:
                    st.metric(name, f"{features_dict[key]:.4f}")
        
        # æ™¶é¢ç‰¹å¾ - å¹¶æ’æ˜¾ç¤º
        st.markdown("##### æ™¶é¢ç‰¹å¾")
        crystal_cols = st.columns(2)
        
        with crystal_cols[0]:
            st.markdown("**002æ™¶é¢**")
            if 'peak_002_position' in features_dict:
                st.metric("å³°ä½ç½®", f"{features_dict['peak_002_position']:.2f}Â°")
            if 'peak_002_fwhm' in features_dict:
                st.metric("FWHM", f"{features_dict['peak_002_fwhm']:.2f}Â°")
            if 'peak_002_Lc' in features_dict:
                st.metric("Lcæ™¶ç²’å°ºå¯¸", f"{features_dict['peak_002_Lc']:.2f} Ã…")
            if 'peak_002_area' in features_dict:
                st.metric("å³°é¢ç§¯", f"{features_dict['peak_002_area']:.4f}")
            if 'peak_002_d_spacing' in features_dict:
                st.metric("å±‚é—´è·", f"{features_dict['peak_002_d_spacing']:.4f} Ã…")
        
        with crystal_cols[1]:
            st.markdown("**100æ™¶é¢**")
            if 'peak_100_position' in features_dict:
                st.metric("å³°ä½ç½®", f"{features_dict['peak_100_position']:.2f}Â°")
            if 'peak_100_fwhm' in features_dict:
                st.metric("FWHM", f"{features_dict['peak_100_fwhm']:.2f}Â°")
            if 'peak_100_La' in features_dict:
                st.metric("Laæ™¶ç²’å°ºå¯¸", f"{features_dict['peak_100_La']:.2f} Ã…")
            if 'peak_100_area' in features_dict:
                st.metric("å³°é¢ç§¯", f"{features_dict['peak_100_area']:.4f}")
            if 'peak_100_d_spacing' in features_dict:
                st.metric("å±‚é—´è·", f"{features_dict['peak_100_d_spacing']:.4f} Ã…")
        
        # æ¯”å€¼ç‰¹å¾
        st.markdown("##### æ¯”å€¼ç‰¹å¾")
        ratio_cols = st.columns(3)
        with ratio_cols[0]:
            if 'La_Lc_ratio' in features_dict:
                st.metric("La/Lcæ¯”å€¼", f"{features_dict['La_Lc_ratio']:.4f}")
        with ratio_cols[1]:
            if 'A002_A100_ratio' in features_dict:
                st.metric("é¢ç§¯æ¯”(A002/A100)", f"{features_dict['A002_A100_ratio']:.4f}")
        with ratio_cols[2]:
            if 'H002_H100_ratio' in features_dict:
                st.metric("é«˜åº¦æ¯”(H002/H100)", f"{features_dict['H002_H100_ratio']:.4f}")
        
        st.markdown('</div>', unsafe_allow_html=True)
        
        # åˆ†æå›¾è¡¨ - å¹¶æ’æ˜¾ç¤º
        st.markdown("#### åˆ†æå›¾è¡¨")
        if file_figs:
            # æ˜¾ç¤ºç¬¬ä¸€ç»„å›¾è¡¨ï¼ˆå¦‚æœæœ‰å¤šä¸ªï¼‰
            cols = st.columns(2)
            with cols[0]:
                st.markdown('<div class="chart-container">', unsafe_allow_html=True)
                st.markdown("**XRDè°±çº¿é¢„å¤„ç†**")
                st.pyplot(file_figs[0])
                st.markdown('</div>', unsafe_allow_html=True)
            
            with cols[1]:
                if len(file_figs) > 1:
                    st.markdown('<div class="chart-container">', unsafe_allow_html=True)
                    st.markdown("**å³°ç‰¹å¾æå–**")
                    st.pyplot(file_figs[1])
                    st.markdown('</div>', unsafe_allow_html=True)
        
        # é‡æ–°åˆ†æåŠŸèƒ½
        st.markdown('<div class="reanalyze-section">', unsafe_allow_html=True)
        st.markdown("#### é‡æ–°åˆ†ææ­¤æ–‡ä»¶")
        
        with st.expander("è°ƒæ•´åˆ†æå‚æ•°"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**002æ™¶é¢èŒƒå›´**")
                reanalyze_002_start = st.number_input(
                    "002èµ·ç‚¹è§’åº¦", 
                    value=float(manual_points.get('002', (15, 35))[0]),
                    min_value=float(10),
                    max_value=float(50),
                    step=0.1,
                    key=f"reanalyze_002_start_{current_index}"
                )
                reanalyze_002_end = st.number_input(
                    "002ç»ˆç‚¹è§’åº¦", 
                    value=float(manual_points.get('002', (15, 35))[1]),
                    min_value=float(10),
                    max_value=float(50),
                    step=0.1,
                    key=f"reanalyze_002_end_{current_index}"
                )
            
            with col2:
                st.markdown("**100æ™¶é¢èŒƒå›´**")
                reanalyze_100_start = st.number_input(
                    "100èµ·ç‚¹è§’åº¦", 
                    value=float(manual_points.get('100', (38, 48))[0]),
                    min_value=float(10),
                    max_value=float(50),
                    step=0.1,
                    key=f"reanalyze_100_start_{current_index}"
                )
                reanalyze_100_end = st.number_input(
                    "100ç»ˆç‚¹è§’åº¦", 
                    value=float(manual_points.get('100', (38, 48))[1]),
                    min_value=float(10),
                    max_value=float(50),
                    step=0.1,
                    key=f"reanalyze_100_end_{current_index}"
                )
            
            reanalyze_bg_mode = st.radio(
                "èƒŒæ™¯æ‰£é™¤æ¨¡å¼",
                options=['precise', 'fast'],
                format_func=lambda x: {'precise': 'ç²¾ç¡®æ¨¡å¼', 'fast': 'å¿«é€Ÿæ¨¡å¼'}[x],
                horizontal=True,
                key=f"reanalyze_bg_mode_{current_index}"
            )
            
            if st.button("é‡æ–°åˆ†æ", key=f"reanalyze_btn_{current_index}"):
                with st.spinner("é‡æ–°åˆ†æä¸­..."):
                    new_manual_points = {
                        '002': (reanalyze_002_start, reanalyze_002_end),
                        '100': (reanalyze_100_start, reanalyze_100_end)
                    }
                    
                    reanalyze_features, reanalyze_figs, _ = analyze_single_file(
                        uploaded_files[current_index],
                        peak_ranges,
                        new_manual_points,
                        reanalyze_bg_mode
                    )
                    
                    if reanalyze_features and reanalyze_figs:
                        st.session_state.batch_results[current_index] = reanalyze_features
                        st.session_state.batch_figs[current_index] = (filename, reanalyze_figs)
                        st.success("é‡æ–°åˆ†æå®Œæˆï¼")
                        st.rerun()
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    else:
        # æœªåˆ†ææ—¶çš„æç¤ºä¿¡æ¯
        st.markdown("""
        <div style="text-align: center; padding: 4rem 2rem; color: #666;">
            <h3>æ¬¢è¿ä½¿ç”¨XRDæ™ºèƒ½ç‰¹å¾æå–å¹³å°</h3>
            <p>è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ XRDæ•°æ®æ–‡ä»¶å¹¶è®¾ç½®åˆ†æå‚æ•°</p>
            <p>æ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶ï¼Œè‡ªåŠ¨æå–æ™¶ç²’å°ºå¯¸ã€å †å å±‚æ•°ç­‰å…³é”®ç‰¹å¾</p>
        </div>
        """, unsafe_allow_html=True)
        
        # åŠŸèƒ½ç‰¹ç‚¹å±•ç¤º
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("""
            <div class="metric-card">
                <h4>æ‰¹é‡å¤„ç†</h4>
                <p>æ”¯æŒåŒæ—¶åˆ†æå¤šä¸ªXRDæ–‡ä»¶</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown("""
            <div class="metric-card">
                <h4>æ™ºèƒ½åˆ†æ</h4>
                <p>è‡ªåŠ¨æå–æ™¶ç²’å°ºå¯¸ç­‰ç‰¹å¾</p>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown("""
            <div class="metric-card">
                <h4>ä¸“ä¸šç®—æ³•</h4>
                <p>åŸºäºç¡¬ç¢³ææ–™ä¼˜åŒ–çš„åˆ†æç®—æ³•</p>
            </div>
            """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()